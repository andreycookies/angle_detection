import torch
import cv2
import numpy as np
from ultralytics import YOLO
import time


def test_gpu_performance():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ GPU vs CPU"""
    
    print("=" * 60)
    print("üîç GPU DIAGNOSTICS")
    print("=" * 60)
    
    # 1. –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    print(f"\n‚úÖ PyTorch version: {torch.__version__}")
    print(f"‚úÖ CUDA available: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"‚úÖ CUDA version: {torch.version.cuda}")
        print(f"‚úÖ GPU device: {torch.cuda.get_device_name(0)}")
        print(f"‚úÖ GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    else:
        print("‚ùå CUDA not available!")
        return
    
    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ GPU
    print("\n" + "=" * 60)
    print("üì¶ LOADING YOLO MODELS")
    print("=" * 60)
    
    try:
        handled_model = YOLO('./models/handled_model.pt')
        raw_model = YOLO('./models/raw_model.pt')
        
        # –Ø–≤–Ω–æ –ø–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ GPU
        device = torch.device('cuda')
        handled_model.to(device)
        raw_model.to(device)
        
        print("‚úÖ Models loaded successfully")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞ –∫–∞–∫–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        first_param = next(handled_model.model.parameters())
        print(f"‚úÖ Model device: {first_param.device}")
        
    except Exception as e:
        print(f"‚ùå Failed to load models: {e}")
        return
    
    # 3. –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    print("\n" + "=" * 60)
    print("üé¨ PERFORMANCE TEST")
    print("=" * 60)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    test_image = np.random.randint(0, 255, (1080, 1920, 3), dtype=np.uint8)
    
    # 4. –¢–µ—Å—Ç CPU inference
    print("\nüêå Testing CPU inference...")
    handled_model.to('cpu')
    
    start = time.time()
    for i in range(3):
        frame_tensor = torch.from_numpy(test_image).float() / 255.0
        frame_tensor = frame_tensor.permute(2, 0, 1).unsqueeze(0)  # CPU tensor
        
        with torch.no_grad():
            _ = handled_model(frame_tensor, verbose=False, device='cpu')
    
    cpu_time = (time.time() - start) / 3
    print(f"   Average CPU time: {cpu_time*1000:.1f} ms ({1/cpu_time:.1f} FPS)")
    
    # 5. –¢–µ—Å—Ç GPU inference (–ù–ï–ü–†–ê–í–ò–õ–¨–ù–´–ô —Å–ø–æ—Å–æ–±)
    print("\n‚ö†Ô∏è  Testing GPU inference (bad way - creating tensor on CPU)...")
    handled_model.to(device)
    
    start = time.time()
    for i in range(10):
        frame_tensor = torch.from_numpy(test_image).float() / 255.0
        frame_tensor = frame_tensor.permute(2, 0, 1).unsqueeze(0)
        frame_tensor = frame_tensor.to(device)  # ‚ùå CPU -> GPU –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ!
        
        with torch.no_grad(), torch.amp.autocast('cuda'):
            _ = handled_model(frame_tensor, verbose=False)
    
    gpu_time_bad = (time.time() - start) / 10
    print(f"   Average GPU time: {gpu_time_bad*1000:.1f} ms ({1/gpu_time_bad:.1f} FPS)")
    print(f"   ‚ö†Ô∏è  This includes CPU->GPU transfer overhead!")
    
    # 6. –¢–µ—Å—Ç GPU inference (–ü–†–ê–í–ò–õ–¨–ù–´–ô —Å–ø–æ—Å–æ–±)
    print("\nüöÄ Testing GPU inference (good way - creating tensor on GPU)...")
    
    start = time.time()
    for i in range(10):
        # –°–æ–∑–¥–∞–µ–º —Ç–µ–Ω–∑–æ—Ä —Å—Ä–∞–∑—É –Ω–∞ GPU
        frame_tensor = torch.from_numpy(test_image).to(device, non_blocking=True).float().div_(255.0)
        frame_tensor = frame_tensor.permute(2, 0, 1).unsqueeze(0).contiguous()
        
        with torch.no_grad(), torch.amp.autocast('cuda'):
            _ = handled_model(frame_tensor, verbose=False)
    
    gpu_time_good = (time.time() - start) / 10
    print(f"   Average GPU time: {gpu_time_good*1000:.1f} ms ({1/gpu_time_good:.1f} FPS)")
    
    # 7. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
    print("\n" + "=" * 60)
    print("üìä RESULTS SUMMARY")
    print("=" * 60)
    print(f"CPU:              {cpu_time*1000:6.1f} ms ({1/cpu_time:5.1f} FPS)")
    print(f"GPU (bad way):    {gpu_time_bad*1000:6.1f} ms ({1/gpu_time_bad:5.1f} FPS) - Speedup: {cpu_time/gpu_time_bad:.1f}x")
    print(f"GPU (good way):   {gpu_time_good*1000:6.1f} ms ({1/gpu_time_good:5.1f} FPS) - Speedup: {cpu_time/gpu_time_good:.1f}x")
    print(f"\nüí° Optimization gain: {gpu_time_bad/gpu_time_good:.1f}x faster with proper GPU usage!")
    
    # 8. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏ GPU
    print("\n" + "=" * 60)
    print("üíæ GPU MEMORY USAGE")
    print("=" * 60)
    print(f"Allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB")
    print(f"Reserved:  {torch.cuda.memory_reserved(0) / 1e9:.2f} GB")
    
    # 9. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print("\n" + "=" * 60)
    print("üí° RECOMMENDATIONS")
    print("=" * 60)
    
    if gpu_time_good < cpu_time * 0.5:
        print("‚úÖ GPU acceleration is working correctly!")
    else:
        print("‚ö†Ô∏è  GPU is not providing expected speedup. Possible issues:")
        print("   - GPU drivers may need update")
        print("   - CUDA toolkit version mismatch")
        print("   - Model size too small to benefit from GPU")
    
    if gpu_time_bad > gpu_time_good * 1.2:
        print("‚ö†Ô∏è  CPU->GPU transfer is a bottleneck!")
        print("   üëâ Make sure to create tensors directly on GPU:")
        print("      torch.from_numpy(data).to(device).float()")
        print("   üëâ NOT: torch.from_numpy(data).float().to(device)")

if __name__ == "__main__":
    test_gpu_performance()